[["index.html", "EVE 109: Molecular Ecology Week 1 Introduction 1.1 Installing R and RStudio 1.2 Tour of RStudio 1.3 Installing packages 1.4 Basic functions in R 1.5 Classes 1.6 Vectors and dataframes 1.7 Subsetting 1.8 Plotting 1.9 Homework", " EVE 109: Molecular Ecology Week 1 Introduction This website provides the material you will need to complete discussion section and homework exercises. Each week, we will go over the commands you need for that week’s assignments. You may work together in class and on homework, but I do expect you to turn in an individual assignment that has been completed on your own and reflects your own understanding of the material. This course is meant to give you an introduction to analyzing genetic data in R, so feel free to take these assignments further where you are interested. Data is fun! 1.1 Installing R and RStudio For most of our analysis in this class, we will work with the programming language “R.” RStudio is a software that provides a nice interface for using R. The very first thing we need to do is install both R and RStudio. The following link has instructions for installing R and RStudio on any laptop: https://datacarpentry.org/R-ecology-lesson/#setup_instructions This website has many tutorials that are relevant to the types of analyses biologists need. Take a moment and install R and RStudio on your laptop. If you are going to be doing homework on a different computer, you will want to install the software on that computer as well.       1.2 Tour of RStudio Next we will take a tour of RStudio as a class. We will cover: The console Scripts Commenting Executing Commands Asking for help       1.3 Installing packages Some special functions or datasets can be downloaded as packages. To install them, we use the install.packages command: install.packages(&quot;babynames&quot;) You only have to install a package once because the package is downloaded to your computer. However, each time you use a package you will need to tell R you are using commands from that package. It’s good practice to place this at the top of your script. library(babynames)       1.4 Basic functions in R R can perform basic mathematical functions, just like a calculator. Type the following into the console and press enter: 10 + 5 # Add ten and five ## [1] 15 To do more complicated analyses, and to make scripts generalizable, we often want to assign values to objects. Type the following in your R script, then execute myvalue &lt;- 10 The arrow &lt;- is how we assign a value to an object. In general, it is better to assign values to objects rather than do math directly on the values. That is because if we want to do several different operations on myvalue but might want to change it later, we only have to change it in one place. Once you have stored a value you can print it, or you can use it to perform further mathematical functions: myvalue #print myvalue ## [1] 10   print(myvalue) #print myvalue ## [1] 10 There’s really no difference between these two ways to print an object   myvalue + 5 #add 5 to myvalue ## [1] 15   newvalue &lt;- myvalue + 5   newvalue ## [1] 15 Note: You can choose any name you want for an object, but be careful! The name should be short (you may have to type it many times), but informative (so you don’t get it confused with other objects). You cannot use spaces and you cannot begin an object name with a number. You can use capitalization and underscore to your advantage, for example: thisIsAnObject or this_is_an_object   1.4.1 Exercise: Write a script to find out what fraction of your life you’ve been at UC Davis Include objects for your age and the number of years you’ve been at Davis. Have the script print the answer.       1.5 Classes R can work with more than just numbers, it can handle a variety of data formats. You can use the function class to check the type of data: class(myvalue) ## [1] &quot;numeric&quot;   But what happens if we assign an object to something other than a number? season &lt;- &quot;fall&quot; class(season) ## [1] &quot;character&quot;   Two somewhat confusing classes are character and factor. character means a string of letters while factor represents categorical data. For plotting and summarizing, we often want factor data. We can convert character data to factor data using the as.factor command: season_factor &lt;- as.factor(season) class(season_factor) ## [1] &quot;factor&quot;       1.6 Vectors and dataframes Usually we want to look at more than one number or value at once. For a single set of values, we can use a vector. To make a vector, we use the c() function (c stands for combine) seasons &lt;- c(&quot;fall&quot;,&quot;winter&quot;,&quot;spring&quot;,&quot;summer&quot;)   Perhaps the most common way to format data is in a dataframe. This is basically a spreadsheet, like you would make in Excel. R has a few example dataframes that we can use. We installed one earlier when we installed the babynames package. Look at the top of this dataframe (the head command gives just the first 5 entries): head(babynames) ## # A tibble: 6 × 5 ## year sex name n prop ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1880 F Mary 7065 0.0724 ## 2 1880 F Anna 2604 0.0267 ## 3 1880 F Emma 2003 0.0205 ## 4 1880 F Elizabeth 1939 0.0199 ## 5 1880 F Minnie 1746 0.0179 ## 6 1880 F Margaret 1578 0.0162 dim(babynames) # how many rows and columns are in the dataframe? ## [1] 1924665 5 dim gives you the dimensions of the dataframe.   Remember, we can always use ? to ask for help. If we want a description of the babynames dataframe: ?babynames       1.7 Subsetting Sometimes we want to examine a specific portion of the data. There are several ways to do this. For a two-dimensional dataframe you can use square bracket notation [x,y] where x is the rows you want and y is the columns you want. Like this: babynames[1:4,c(2,3)] #take the first four rows and columns 2 &amp; 3 ## # A tibble: 4 × 2 ## sex name ## &lt;chr&gt; &lt;chr&gt; ## 1 F Mary ## 2 F Anna ## 3 F Emma ## 4 F Elizabeth Notice the : gives me all the integers between 1 and 4.   You can also ask for columns by name using the $ notation. This means you can use the column name to ask for a single column out of the dataframe. Note that this does not work for rows. head(babynames$name) ## [1] &quot;Mary&quot; &quot;Anna&quot; &quot;Emma&quot; &quot;Elizabeth&quot; &quot;Minnie&quot; &quot;Margaret&quot;   You can use the subset function to ask for rows that meet certain criteria. Notice the double ==. You use this when you are comparing values. myname &lt;- &quot;Rachael&quot; mydata &lt;- subset(babynames,name==myname) # take just the entries where name = &quot;Rachael&quot; head(mydata) ## # A tibble: 6 × 5 ## year sex name n prop ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1880 F Rachael 12 0.000123 ## 2 1881 F Rachael 8 0.0000809 ## 3 1882 F Rachael 8 0.0000692 ## 4 1883 F Rachael 9 0.0000750 ## 5 1884 F Rachael 7 0.0000509 ## 6 1885 F Rachael 8 0.0000564 dim(mydata) ## [1] 158 5       1.8 Plotting R is great for plotting. The simplest type of plot is just an x,y scatterplot: plot(mydata$year,mydata$prop) Use ? to look at the options for plotting. For example, here I add more informative axis labels and choose a nice color for the points: plot(mydata$year,mydata$prop, ylab=&quot;Proportion of babies&quot;, xlab=&quot;Year&quot;, col=&quot;aquamarine4&quot;) Notice that I used new lines (returns) to make this more readable. R doesn’t care where you put white space, so use it to make your code as organized as possible.   Of course, it’s better if color is informative, so lets use it to learn something. Isn’t it weird that there are a bunch of points at 0 and other points with higher proportions during the same time frame? Maybe those points are different in some way. Lets try this: plot(mydata$year,mydata$prop, ylab=&quot;Proportion of babies&quot;, xlab=&quot;Year&quot;, col=as.factor(mydata$sex)) 1.8.1 Exercise: Describe this plot in plain english. What conclusions can we draw?         1.9 Homework Each week, you will submit a script for homework. While most of the concepts you will need will be taught during section, you may have to look up some commands online (remember, Google is your friend!). The top of your script should contain commented lines with the following: #Name #Date #EVE 109 Homework #Week ##   I should be able to execute the script. When printed answers are expected, you should store them in an object and have a line of code above should have a comment telling me where the answer is printed. For example: #Answer to Question 1 print(myvalue) ## [1] 10   If the answer requires a plot, follow the same format, with a comment indicating that this plot answers a homework question: #Answer to Question 2 plot(mydata$year,mydata$prop)   Show your work and comment your code. You will only receive full credit for clean, organized code   1.9.1 Homework 1: Write a script that does the following: Plot the use of your name over time (Or pick a different name). Only include points for one sex. What proportion of babies had your name when it was most popular? In which year was your name most popular? "],["molecular-markers.html", "Week 2 Molecular Markers 2.1 Paths 2.2 Reading in data from spreadsheets 2.3 Simple capture recapture example 2.4 Homework", " Week 2 Molecular Markers 2.1 Paths For this course, I will upload the datasets you need to this website and you will download them to your own computer. You will then need to figure out how tell R where to find them. You can find out what directory you are currently in using the getwd() command: getwd() ## [1] &quot;/Users/rachaelbay/Documents/Courses/Molecular Ecology/2021/Website&quot; Directories are hierarchical: the represent folders within folders just like you view them when you navigate with your mouse. You can also set which directory R will use to look for files. This is called your ‘working directory’ and you can set it using setwd(). For example, if I create a folder called \"EVE109 inside my documents folder where I want to store all my materials for this class, I can then tell R I want it to look in that directory for files: setwd(&quot;~/Documents/EVE109&quot;) If you get an error that your file cannot be found, a good first step is to check your working directory.       2.2 Reading in data from spreadsheets Today we will be working with data from the paper we read in class. You can download the dataset here A lot of data we use is stored in spreadsheets. However, when we store them in a normal Excel format (.xlsx) they come with a lot of extra formatting that R has trouble reading. One way to avoid this is to store them in a comma separated value format (.csv). Open “wombats.csv” in a text editor and look at it. It’s not easy for us to read, but you can see that it is a very simple format where each entry is separated by a comma. You were able to open it in a spreadsheet program and R can read it easily. If you are making your own data, you can save spreadsheets as .csv files from most spreadsheet programs. Now we want to read that data into RStudio. We can do that using the command read.csv. Remember do assign the resulting data frame to an object: data &lt;- read.csv(&quot;data/wombats.csv&quot;) # Read in a file Remember, we can look at the top of the dataframe using head: head(data) ## No.captures total males females ## 1 1 25 18 7 ## 2 2 11 7 4 ## 3 3 10 7 3 ## 4 4 10 6 4 ## 5 5 9 6 3 ## 6 6 11 6 5 This is data from the paper we read this week by Banks et al. (2003) using genetic analysis to monitor northern hairy-nosed wombats. The table represents the data shown in Figure 1, so individuals have already been identified and we’re looking at the number of times each was recaptured.       2.3 Simple capture recapture example Next we will learn a simple way to make population size estimations. We will use the capwire package to do this. Remember how to install and load a package? install.packages(&quot;capwire&quot;) library(capwire) The manual for capwire can be found online here   Okay, now lets make up some data. Luckily, capwire has a function that allows you to simulate data. Look up the function simCapture. Notice there are three different arguments we need to specify (we can ignore return.cap.probs because it has a default that we do not want to change). Using this function we’ll simulate a population of 300, from which we have 50 samples. This distribution function just means that every individual has an equal probability of being captured. sim &lt;- simCapture(n=300,s=50,dist.func=drawCapRatesUnif(0.1,1)) # Simulate capture data sim ## capture.class No.Ind ## 1 1 40 ## 2 2 5 Now that we have simulated data, we can use one of the fitEcm function to estimate population size. What arguments do we need for that function? Notice that the help page tells you what format your data should be in. ecm &lt;- fitEcm(data=sim,max.pop=500) # estimate population size The fitEcm page also describes that output. We are most interested in the population size estimate, which is called ml.pop.size. We can extract that using: ecm$ml.pop.size ## [1] 228 How much uncertainty is there in our estimate? We can use bootstrap resampling to create confidence intervals. Look up the command boostrapCapwire boot &lt;- bootstrapCapwire(x=ecm,bootstraps=1000,CI=c(0.025,0.975)) # estimate confidence intervals boot ## $ml.pop.size ## [1] 228 ## ## $conf.int ## 2.5% 97.5% ## 119 500 Using this 95% confidence interval means there is a 95% chance the real answer is within that range. Why is it so large?! What happens if we have more samples?       2.4 Homework Now that we know how to estimate population sizes, we will use the wombat data from before. Start a new script for this. 2.4.1 Homework 2: Write a script that does the following: Read in “wombats.csv” Estimate the total population size. Estimate confidence intervals for the total population size. Estimate male and female population sizes. What is the ratio of males to females in this population? "],["genetic-diversity.html", "Week 3 Genetic Diversity 3.1 Manipulating dataframes 3.2 Using the adegenet package to calulate heterozygosity 3.3 Homework", " Week 3 Genetic Diversity 3.1 Manipulating dataframes As we saw last week, the most common class we work with in R is a dataframe. This week, we’ll learn a few more ways to manipulate dataframes. This time we’ll use the built in palmerpenguins dataset: install.packages(&quot;palmerpenguins&quot;) library(palmerpenguins) head(penguins) ## # A tibble: 6 × 9 ## species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex year mean ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Adelie Torgersen 39.1 18.7 181 3750 male 2007 997. ## 2 Adelie Torgersen 39.5 17.4 186 3800 female 2007 1011. ## 3 Adelie Torgersen 40.3 18 195 3250 female 2007 876. ## 4 Adelie Torgersen NA NA NA NA &lt;NA&gt; 2007 NA ## 5 Adelie Torgersen 36.7 19.3 193 3450 female 2007 925. ## 6 Adelie Torgersen 39.3 20.6 190 3650 male 2007 975. One quick way to explore the data is using summary: summary(penguins) ## species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g ## Adelie :152 Biscoe :168 Min. :32.10 Min. :13.10 Min. :172.0 Min. :2700 ## Chinstrap: 68 Dream :124 1st Qu.:39.23 1st Qu.:15.60 1st Qu.:190.0 1st Qu.:3550 ## Gentoo :124 Torgersen: 52 Median :44.45 Median :17.30 Median :197.0 Median :4050 ## Mean :43.92 Mean :17.15 Mean :200.9 Mean :4202 ## 3rd Qu.:48.50 3rd Qu.:18.70 3rd Qu.:213.0 3rd Qu.:4750 ## Max. :59.60 Max. :21.50 Max. :231.0 Max. :6300 ## NA&#39;s :2 NA&#39;s :2 NA&#39;s :2 NA&#39;s :2 ## sex year mean ## female:165 Min. :2007 Min. : 738.9 ## male :168 1st Qu.:2007 1st Qu.: 950.9 ## NA&#39;s : 11 Median :2008 Median :1076.6 ## Mean :2008 Mean :1115.9 ## 3rd Qu.:2009 3rd Qu.:1257.5 ## Max. :2009 Max. :1646.3 ## NA&#39;s :2 For quantitative columns, this gives you basic summary statistics and for categorical columns it gives you counts of each value. We could have also looked at the categorical data using the table command: table(penguins$Species) ## Warning: Unknown or uninitialised column: `Species`. ## &lt; table of extent 0 &gt;   Let’s take just the quantitative data for a moment: quant &lt;- penguins[,3:6] head(quant) ## # A tibble: 6 × 4 ## bill_length_mm bill_depth_mm flipper_length_mm body_mass_g ## &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 39.1 18.7 181 3750 ## 2 39.5 17.4 186 3800 ## 3 40.3 18 195 3250 ## 4 NA NA NA NA ## 5 36.7 19.3 193 3450 ## 6 39.3 20.6 190 3650 For easy summaries of rows or columns, we can us the commands colSums, colMeans, rowSums, and rowMeans means &lt;- rowMeans(quant) Maybe we want to add a column to the initial iris dataframe that has the mean of the different measurements. We can do that in two different ways: penguins$mean &lt;- rowMeans(quant) # Caluclate and name the new column at the same time or... means2 &lt;- rowMeans(quant) # Calculate means newpenguins &lt;- cbind(penguins,means2) # cbind (column bind) to iris dataframe head(newpenguins) ## species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex year mean ## 1 Adelie Torgersen 39.1 18.7 181 3750 male 2007 997.200 ## 2 Adelie Torgersen 39.5 17.4 186 3800 female 2007 1010.725 ## 3 Adelie Torgersen 40.3 18.0 195 3250 female 2007 875.825 ## 4 Adelie Torgersen NA NA NA NA &lt;NA&gt; 2007 NA ## 5 Adelie Torgersen 36.7 19.3 193 3450 female 2007 924.750 ## 6 Adelie Torgersen 39.3 20.6 190 3650 male 2007 974.975 ## means2 ## 1 997.200 ## 2 1010.725 ## 3 875.825 ## 4 NA ## 5 924.750 ## 6 974.975 3.2 Using the adegenet package to calulate heterozygosity Today we’ll use microsatellite data from the Weeks et al. (2017) paper using genetic analysis to look at the effects of population recovery after an introduction. You can download it here. Let’s read in this file: data &lt;- read.csv(&quot;data/weeks_genotypes.csv&quot;) # Read in a file Take a look at the data: head(data) ## ID Pop Year LOC1 LOC2 LOC3 LOC4 LOC5 LOC6 LOC7 LOC8 LOC9 LOC10 ## 1 1 MtBuller 2010 311/311 245/249 303/303 195/201 218/218 211/211 321/321 240/240 157/157 113/113 ## 2 2 MtBuller 2010 311/311 245/249 303/303 195/201 218/218 211/211 321/321 240/240 157/157 113/113 ## 3 3 MtBuller 2010 311/311 245/249 303/303 NA/NA 218/218 211/211 321/321 240/240 157/157 113/113 ## 4 4 MtBuller 2010 311/311 249/249 303/303 195/195 218/218 211/211 321/321 240/240 157/157 113/113 ## 5 5 MtBuller 2010 309/311 249/249 303/303 195/201 218/218 211/211 321/321 240/240 157/157 113/115 ## 6 6 MtBuller 2010 309/311 NA/NA 303/303 201/201 218/218 211/211 321/321 240/240 157/157 113/115 ## LOC11 LOC12 LOC13 LOC14 LOC15 LOC16 LOC17 LOC18 LOC19 LOC20 LOC21 LOC22 ## 1 178/178 125/125 309/318 119/119 144/146 214/214 241/241 160/160 150/150 117/117 141/141 137/137 ## 2 178/178 125/125 309/309 119/148 144/146 214/214 241/241 160/160 150/150 117/117 141/141 137/137 ## 3 178/178 125/125 309/309 119/119 144/144 214/216 241/241 160/160 150/150 117/117 141/141 137/137 ## 4 178/178 125/125 309/309 119/119 144/146 214/214 241/241 160/160 150/150 117/117 141/141 137/137 ## 5 178/178 125/125 309/318 148/148 144/146 216/216 241/241 160/160 150/150 117/117 141/141 137/141 ## 6 178/178 125/125 309/318 119/148 144/144 214/214 241/241 160/160 150/150 117/117 141/141 137/137 ## LOC23 LOC24 ## 1 157/157 177/177 ## 2 157/157 177/177 ## 3 157/157 177/177 ## 4 157/157 177/177 ## 5 157/157 177/177 ## 6 157/157 177/177 The first column is an id assigned to each individual. The second column gives the populations from which the individual was sampled. The third column gives the year of sampling. The remaining columns give the microsatellite data. Each individual has two numbers which represent the fragment lengths (read on a gel). If the two fragment lengths are the same, the individual is a heterozygote. If they are different, the individual is a homozygote. We will use the package adegenet to read in the microsatellite data and calculate heterozygosity. The manual for this package is here. Install the package and call the library: install.packages(&quot;adegenet&quot;) library(adegenet)   The first thing we need to do is let the adegenet read in the microsatellite data. We can do this with the df2genind. Let’s ask for help on that command: ?df2genind Look at the arguments. How can we format our allele data to meet the requirements of the package? alleles &lt;- data[,4:ncol(data)] The function ncol gives us the number of columns. So here we are asking for all columns except the first three, which do not contain genotype data. Okay, let’s see if that works genind &lt;- df2genind(alleles,sep=&quot;/&quot;,NA.char=&quot;NA/NA&quot;) summary(genind) ## ## // Number of individuals: 524 ## // Group sizes: 524 ## // Number of alleles per locus: 5 5 10 7 8 3 7 16 3 11 10 2 6 10 5 2 10 2 5 3 2 10 9 4 ## // Number of alleles per group: 155 ## // Percentage of missing data: 1.03 % ## // Observed heterozygosity: 0.12 0.68 0.29 0.6 0.48 0.3 0.36 0.38 0.35 0.64 0.43 0.22 0.54 0.6 0.5 0.21 0.38 0.25 0.25 0.17 0.17 0.39 0.26 0.25 ## // Expected heterozygosity: 0.12 0.64 0.36 0.7 0.58 0.32 0.5 0.56 0.51 0.74 0.56 0.45 0.64 0.61 0.63 0.25 0.44 0.46 0.29 0.19 0.35 0.49 0.33 0.38   The object summary has most of the information we want: results &lt;- summary(genind) names(results) # Show the different output values we can look at ## [1] &quot;n&quot; &quot;n.by.pop&quot; &quot;loc.n.all&quot; &quot;pop.n.all&quot; &quot;NA.perc&quot; &quot;Hobs&quot; &quot;Hexp&quot; results$Hobs # Show observed heterozygosity ## LOC1 LOC2 LOC3 LOC4 LOC5 LOC6 LOC7 LOC8 LOC9 LOC10 ## 0.1150097 0.6812749 0.2913386 0.5984405 0.4799235 0.2972973 0.3556405 0.3754864 0.3512476 0.6382979 ## LOC11 LOC12 LOC13 LOC14 LOC15 LOC16 LOC17 LOC18 LOC19 LOC20 ## 0.4335260 0.2160612 0.5393474 0.5965583 0.4990366 0.2103250 0.3754789 0.2471264 0.2480620 0.1739962 ## LOC21 LOC22 LOC23 LOC24 ## 0.1685824 0.3850575 0.2553191 0.2528736   Notice that observed and expected heterozygosity have been calculated, but across the entire dataset. What if we supply different populations? We use the seppop function to tell it we want separate measurements for each population genindPop &lt;- df2genind(alleles,sep=&quot;/&quot;, NA.char=&quot;NA/NA&quot;, pop=data$Pop) genindPop &lt;- seppop(genindPop) genindPop ## $MtBuller ## /// GENIND OBJECT ///////// ## ## // 420 individuals; 24 loci; 155 alleles; size: 316.4 Kb ## ## // Basic content ## @tab: 420 x 155 matrix of allele counts ## @loc.n.all: number of alleles per locus (range: 2-16) ## @loc.fac: locus factor for the 155 columns of @tab ## @all.names: list of allele names for each locus ## @ploidy: ploidy of each individual (range: 2-2) ## @type: codom ## @call: .local(x = x, i = i, j = j, pop = ..1, treatOther = ..2, quiet = ..3, ## drop = drop) ## ## // Optional content ## @pop: population of each individual (group size range: 420-420) ## ## $MtHigginbotham ## /// GENIND OBJECT ///////// ## ## // 104 individuals; 24 loci; 155 alleles; size: 102.9 Kb ## ## // Basic content ## @tab: 104 x 155 matrix of allele counts ## @loc.n.all: number of alleles per locus (range: 2-16) ## @loc.fac: locus factor for the 155 columns of @tab ## @all.names: list of allele names for each locus ## @ploidy: ploidy of each individual (range: 2-2) ## @type: codom ## @call: .local(x = x, i = i, j = j, pop = ..1, treatOther = ..2, quiet = ..3, ## drop = drop) ## ## // Optional content ## @pop: population of each individual (group size range: 104-104)   Notice the two locations are now separate. We can get the heterozygosity separately for each population: MtBuller &lt;- summary(genindPop$MtBuller) MtHiggenbotham &lt;- summary(genindPop$MtHigginbotham) MtBuller$Hobs # Observed heterozygosity for all Mt Buller Samples ## LOC1 LOC2 LOC3 LOC4 LOC5 LOC6 LOC7 LOC8 LOC9 LOC10 ## 0.1196172 0.6526055 0.2120482 0.5649038 0.3937947 0.2583732 0.2911695 0.3325359 0.3381295 0.6201923 ## LOC11 LOC12 LOC13 LOC14 LOC15 LOC16 LOC17 LOC18 LOC19 LOC20 ## 0.3317422 0.2696897 0.5083532 0.5751790 0.4892086 0.2625298 0.2559809 0.3086124 0.1654676 0.1527446 ## LOC21 LOC22 LOC23 LOC24 ## 0.1360382 0.3110048 0.1558753 0.1531100 MtBuller$Hexp # Expected heterozygosity for all Mt Buller Samples ## LOC1 LOC2 LOC3 LOC4 LOC5 LOC6 LOC7 LOC8 LOC9 LOC10 ## 0.1129982 0.6064596 0.2329279 0.6085111 0.4022334 0.2458735 0.2869544 0.3583595 0.3399151 0.6384350 ## LOC11 LOC12 LOC13 LOC14 LOC15 LOC16 LOC17 LOC18 LOC19 LOC20 ## 0.3431457 0.3045010 0.5145363 0.5734332 0.5079217 0.3030058 0.2639076 0.3282291 0.1647056 0.1750275 ## LOC21 LOC22 LOC23 LOC24 ## 0.1629775 0.3484438 0.1637021 0.1735194       3.2.1 Plotting heterozygosity Let’s use a barplot to look at variation in heterozygostiy across all our markers: barplot(MtBuller$Hobs) When we have a bunch of markers, we often take the mean across all those markers: mean(MtHiggenbotham$Hobs) # Mean observed heterozygosity in the Mt Higgenbotham population ## [1] 0.5262125 Compare this value to the paper.       3.3 Homework Now that we know how to estimate observed and expected heterozygosity, we’ll look at changes over time. Start a new script for your homework 3.3.1 Homework 3: Write a script that does the following: Read in “genotypes.csv” and subset the dataframe to Mt Buller samples only. How many samples do you have from each year? Calculate mean observed heterozygosity for each year. Put these into a single dataframe. Calculate mean expected heterozygosity for each year. Add these to the dataframe from question 2. Plot mean expected heterozygosity over time. Add a vertical lines to your plot to show when introductions took place (hint - use the abline command) "],["population-structure.html", "Week 4 Population Structure 4.1 The aggregate and apply functions 4.2 Running a clustering analysis and deciding on a K value 4.3 The Q matrix 4.4 Plotting 4.5 Homework", " Week 4 Population Structure 4.1 The aggregate and apply functions Today we’ll two useful functions that you can use for dataframes, apply and aggregate. Let’s use the palmerpenguins dataset again: library(palmerpenguins) head(penguins) ## # A tibble: 6 × 9 ## species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex year mean ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Adelie Torgersen 39.1 18.7 181 3750 male 2007 997. ## 2 Adelie Torgersen 39.5 17.4 186 3800 female 2007 1011. ## 3 Adelie Torgersen 40.3 18 195 3250 female 2007 876. ## 4 Adelie Torgersen NA NA NA NA &lt;NA&gt; 2007 NA ## 5 Adelie Torgersen 36.7 19.3 193 3450 female 2007 925. ## 6 Adelie Torgersen 39.3 20.6 190 3650 male 2007 975.   One thing we might want to do is find out which individual has the highest value for each column. We can use the apply function to do the same thing to each column: ?apply apply(penguins[,3:6],MARGIN=2,which.max) ## bill_length_mm bill_depth_mm flipper_length_mm body_mass_g ## 186 20 216 170 Notice that we only used columns 3-6 because these are numeric (rather than categorical). The second argument, MARGIN, is asking whether we should be doing the function for each row (MARGIN=1), or each column (MARGIN=2). The final argument is the function we want to use. which.max asks for the index (in this case, which row) has the maximum value.   Another useful function is aggregate. Sometimes you might want to summarize groups within a dataframe. aggregate does this easily. For example, what if we want to average values for each species: ?aggregate aggregate(penguins[,3:6],by=list(penguins$species),mean) ## Group.1 bill_length_mm bill_depth_mm flipper_length_mm body_mass_g ## 1 Adelie NA NA NA NA ## 2 Chinstrap 48.83382 18.42059 195.8235 3733.088 ## 3 Gentoo NA NA NA NA This gives us the mean for each set of rows that share a value in the “species” column. The second argument, by, tells how to group. The third argument is the function to use.   These commands will come in handy today! Let’s take just the quantitative data for a moment:       4.2 Running a clustering analysis and deciding on a K value The example file for use in class today can be downloaded here A common way to analyze population structure is using hierarchical clustering. Probably the most heavily used program to do this is called STRUCTURE. However, we’ll stick to similar tools you can use in R. Today we’ll use LEA for our clustering analysis. LEA cannot be downloaded from the normal R database, so use the following code: install.packages(&quot;BiocManager&quot;) BiocManager::install(&quot;LEA&quot;) Then load the library library(LEA)   For the analysis today, we’re going to use SNP data. Open the file you downloaded called week4_example.geno using a text editor. This file is in geno format. That means there is one line per individual and genotypes are coded as 0,1,or 2. 0 and 2 are homozygotes and 1 is a heterozygote. 9 means missing data. Notice that this only works when you are looking at SNPs with just 2 alleles (biallelic).   We’ll use the package LEA to read this file in and look at population structure. Make sure you have the right path!! project &lt;- snmf(&quot;data/week4_example.geno&quot;, K = 1:5, entropy = TRUE, repetitions = 10, project = &quot;new&quot;) Remember what K values are? That means ‘how many populations should we try to split this data in to?’ Here we run 10 repetitions per K value. That’s because each run is slightly different so you want to have confidence in your answer. You’ll see what entropy means in a second. You’ll get a bunch of output in your console when you run this command. It will also create a new folder on your computer called “example.snmf.” It contains a bunch of different files for each run of the clustering program. We will be able to use these files to analyze and visualize our results.   Now we’ll chose the “best” value of K. Know that there are several ways to do this and they don’t always agree, so this should be interpreted with caution. Here we will use cross-entropy loss. This basically asks how consistently our model is able to categorize the samples. The lower the cross-entropy the better the model is doing. Let’s plot all the values of K: plot(project,col=&quot;blue&quot;,pch=19)   When I ran this, K=4 had the lowest cross entropy. This plot might look slightly different each time you run it.       4.3 The Q matrix Now that we’ve decided which value of K to look at, we can look at the ancestry estimates for each individual. qmatrix &lt;- Q(project,K=4,run=1)   This command pulls out the ancestry matrix (called the Q matrix) for the first run with K=3. Let’s look at the Q matrix. head(qmatrix) ## V1 V2 V3 V4 ## [1,] 0.077392600 0.715395000 0.207112000 0.000099991 ## [2,] 0.035214600 0.964585000 0.000099982 0.000099982 ## [3,] 0.000099982 0.478033000 0.521767000 0.000099982 ## [4,] 0.000099990 0.604355000 0.138440000 0.257105000 ## [5,] 0.306409000 0.000099982 0.693391000 0.000099982 ## [6,] 0.000099982 0.000099982 0.056404800 0.943395000   Here, each row is an individual and each column is one of the inferred clusters. First, lets give the individuals “IDs” as rownames. You’ll see that this is important later. Next, one thing we could do is look at which cluster has the highest ancestry for each individual. The which.max function just gives you the index (which column in this case) of the highest value. rownames(qmatrix) &lt;- 1:nrow(qmatrix) maxCluster &lt;- apply(qmatrix,1,which.max) maxCluster ## 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 ## 2 2 3 2 3 4 3 2 4 3 3 2 3 3 1 1 2 1 4 1 1 4 1 2 3 1 2 4 2 4 3 3 3 4 ## 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 ## 2 1 4 4 3 4 4 2 1 3 1 2 1 4 1 1   If we pretend maxCluster gives refers to the population from which the individual came, we can use the aggregate function to look at average cluster membership across each population: aggregate(qmatrix,by=list(maxCluster),mean) ## Group.1 V1 V2 V3 V4 ## 1 1 0.73102115 0.009596734 0.11205988 0.14732209 ## 2 2 0.01983594 0.833421000 0.07368114 0.07306200 ## 3 3 0.07268187 0.075687121 0.81715346 0.03447748 ## 4 4 0.08579882 0.080564458 0.03620655 0.79743025 NOTE: Although we are using maxCluster as an indicator of population here, usually we would use some sort of a priori information we had, such as geographic location or maybe morphological species, depending on our question. This distinction will be important for your homework!       4.4 Plotting Now lets plot the ancestry results. Basically, we just want to make a barplot of the qmatrix. You can do that with the barchart function in the LEA package: barchart(project, K=4, run=1, border=NA, space=0) ## $order ## [1] 15 16 18 20 21 23 26 36 43 45 47 49 50 1 2 4 8 12 17 24 27 29 35 42 46 6 9 19 22 28 30 34 37 ## [34] 38 40 41 48 3 5 7 10 11 13 14 25 31 32 33 39 44 We can also try to label each bar with information. For example, lets try to label with the population assignment that we inferred, maxCluster: barchart(project, K=4, run=1, border=NA, space=0) -&gt; bp axis(1,at=1:length(bp$order),label=maxCluster[bp$order],las=2,cex.axis=0.4)   The grayscale is boring!! R has many many options for color packages and you could even make one of your own! For example, here is a fun one inspired by favorite La Croix flavors! install.packages(&quot;devtools&quot;) devtools::install_github(&quot;johannesbjork/LaCroixColoR&quot;) And now use it in our bar chart: library(LaCroixColoR) my.cols=lacroix_palette(&quot;PassionFruit&quot;,n=4,type=&quot;discrete&quot;) barchart(project, K=4, run=1, border=NA, space=0,col=my.cols) -&gt; bp axis(1,at=1:length(bp$order),label=maxCluster[bp$order],las=2,cex.axis=0.4) 4.5 Homework For homework, we will analyze the data from Sendell-Price et al. (2021). I am providing two relevant files: price_genos.geno is the genotypes file for a subset of the SNP markers used in the paper price_pops.csv is a file with the sampling location info for each indidividual included in the genotypes file. Note that they are in the same order as in the genotypes file. 4.5.1 Homework 4: Write a script that does the following: Read in the metadata file. Print a table showing how many individuals we have from each population. Run the clustering analysis using the snmf command. Create a cross-entropy plot. Get a Q matrix for K=5 (used in the paper). Add sample IDs from the metadata file as rownames to the Q matrix. Print the head of the Q matrix. For the “TAS” population, what are the average ancestry proportions from each cluster? Plot the ancestry barplot with populations labelled at the bottom. Color palette is up to you :) "],["haplotype-networks.html", "Week 5 Haplotype networks 5.1 Indexing 5.2 Using table to count across multiple columns 5.3 Creating a haplotype network 5.4 Homework", " Week 5 Haplotype networks 5.1 Indexing Today we’ll use the “Arthritis” dataset from the vcd package to learn some functions. Let’s install it: install.packages(&quot;vcd&quot;) library(vcd) data(Arthritis) ?Arthritis head(Arthritis) ## ID Treatment Sex Age Improved ## 1 57 Treated Male 27 Some ## 2 46 Treated Male 29 None ## 3 77 Treated Male 30 None ## 4 17 Treated Male 32 Marked ## 5 36 Treated Male 46 Marked ## 6 23 Treated Male 58 Marked   R and other programing languages use “indexing” to subset data. Indexing uses the order of entries (for example values in a vector or rows in a dataframe) to isolate particular entries. We’ve already used indexing to subset, maybe without even knowing it. For example, we know the command below gives us the first through fourth rows and the first through third columns. The numbers inside the brackes are called “indexes.” Arthritis[1:4,1:3] ## ID Treatment Sex ## 1 57 Treated Male ## 2 46 Treated Male ## 3 77 Treated Male ## 4 17 Treated Male   We can also use indexing to subet by a certain criteria. The command which returns indexes for all entries that meet a certain criteria. We saw a similar effect last week when we used which.max, but which is a more general command: ind &lt;- which(Arthritis$Sex==&quot;Male&quot;) ind ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 42 43 44 45 46 47 48 49 50 51 52 This gives us the indexes of the rows in the Arthritis data frame where the patient was male. If we want to retrieve these rows, we can use that vector to pull out those rows: Arthritis[ind,] ## ID Treatment Sex Age Improved ## 1 57 Treated Male 27 Some ## 2 46 Treated Male 29 None ## 3 77 Treated Male 30 None ## 4 17 Treated Male 32 Marked ## 5 36 Treated Male 46 Marked ## 6 23 Treated Male 58 Marked ## 7 75 Treated Male 59 None ## 8 39 Treated Male 59 Marked ## 9 33 Treated Male 63 None ## 10 55 Treated Male 63 None ## 11 30 Treated Male 64 None ## 12 5 Treated Male 64 Some ## 13 63 Treated Male 69 None ## 14 83 Treated Male 70 Marked ## 42 9 Placebo Male 37 None ## 43 14 Placebo Male 44 None ## 44 73 Placebo Male 50 None ## 45 74 Placebo Male 51 None ## 46 25 Placebo Male 52 None ## 47 18 Placebo Male 53 None ## 48 21 Placebo Male 59 None ## 49 52 Placebo Male 59 None ## 50 45 Placebo Male 62 None ## 51 41 Placebo Male 62 None ## 52 8 Placebo Male 63 Marked Note that we could have just as easily done this: Arthritis[Arthritis$Sex==&quot;Male&quot;,] When you do a command like this R finds the indexes and returns the rows for you, without you having to think about indexes. However, it can still be useful to know how indexes work, as we will see in the section today.       5.2 Using table to count across multiple columns Previously we used the table function to count the number of times each value was observed in a specific column. Today we’ll use the same function to create a matrix of counts across two different variables. First let’s get some data. Install the package vcd, load the library and pull up the Arthritis dataset: Notice that several of the columns are categorical. That means we can count how many times a certain category shows up. Before, we made a table with just one column, like this: table(Arthritis$Improved) ## ## None Some Marked ## 42 14 28 But what if we want to sort by another factor simultaneously. For example, we can see improvement based on treatment: table(Arthritis$Treatment,Arthritis$Improved) ## ## None Some Marked ## Placebo 29 7 7 ## Treated 13 7 21       5.3 Creating a haplotype network Today we will use mtDNA sequences from an example dataset to learn to create a haplotype network. The package we will use is called pegas. Install this package and load the library. install.packages(&quot;pegas&quot;) library(pegas) We will take advantage of a dataset called woodmouse that is part of the pegas package: data(woodmouse) woodmouse ## 15 DNA sequences in binary format stored in a matrix. ## ## All sequences of same length: 965 ## ## Labels: ## No305 ## No304 ## No306 ## No0906S ## No0908S ## No0909S ## ... ## ## Base composition: ## a c g t ## 0.307 0.261 0.126 0.306 ## (Total: 14.47 kb) Notice that woodmouse only has 15 individuals. We want to work with a few more, so we will artificially expand the dataset. We can do this by sampling with replacement using the command sample. Here we create a vector of the numbers 1:15, randomly sampled 100 times. We use that to choose individuals to sample (some multiple times) from the woodmouse dataset: data &lt;- woodmouse[sample(1:15,size=100,replace=T),] data ## 100 DNA sequences in binary format stored in a matrix. ## ## All sequences of same length: 965 ## ## Labels: ## No0910S ## No1208S ## No0912S ## No306 ## No1103S ## No1208S ## ... ## ## Base composition: ## a c g t ## 0.307 0.261 0.126 0.306 ## (Total: 96.5 kb)   Now we have 100 individuals! First, let’s make up some metadata that we can use later. You can use the labels function to pull sample names out of data. We will also assign each sample to a random “north” or “south” location. loc &lt;- sample(c(&quot;north&quot;,&quot;south&quot;),100,replace=T) names &lt;- labels(data) meta &lt;- data.frame(cbind(names,loc)) head(meta) ## names loc ## 1 No0910S south ## 2 No1208S south ## 3 No0912S south ## 4 No306 south ## 5 No1103S south ## 6 No1208S north NOTE: If we were doing this on real data, we would usually read in the populations from a spreadsheet. Here we just make them up to illustrate how the process works!   When we sequence DNA, some individuals will have the same haplotype. So the first step is to check how many haplotypes there are and which individuals share haplotypes. We do this with the haplotype function: hap &lt;- haplotype(data) hap ## ## Haplotypes extracted from: data ## ## Number of haplotypes: 15 ## Sequence length: 965 ## ## Haplotype labels and frequencies: ## ## I II III IV V VI VII VIII IX X XI XII XIII XIV XV ## 4 4 6 7 12 4 10 11 8 2 10 8 6 6 2   In the output you can see the frequencies of each of the 15 haplotypes. Now we want a list of which individuals have which haplotypes: hapInfo &lt;- stack(setNames(attr(hap,&quot;index&quot;),rownames(hap))) head(hapInfo) ## values ind ## 1 1 I ## 2 12 I ## 3 55 I ## 4 80 I ## 5 2 II ## 6 6 II This command is a bit complicated. Briefly, it takes a list of individuals for each haplotype, and makes a dataframe that tells you which individual has which haplotype. The tricky part is that it returns the indexes of the individuals, not their actual data. Let’s change the column names to make more sense: names(hapInfo) &lt;- c(&quot;index&quot;,&quot;haplotype&quot;)   Now, we can use that index to merge the meta dataframe with the hapInfo data frame: merged &lt;- data.frame(cbind(hapInfo,meta[hapInfo$index,])) head(merged) ## index haplotype names loc ## 1 1 I No0910S south ## 12 12 I No0910S north ## 55 55 I No0910S north ## 80 80 I No0910S north ## 2 2 II No1208S south ## 6 6 II No1208S north   Great! Now lets start to make a haplotype network! This is pretty simple in pegas using the haploNet function. Below we plot the network for out haplotype set hap. We use the “freq” attribute to size the circles so that each circle is proportional to the number of samples with that haplotype: net &lt;- haploNet(hap) plot(net,size=attr(net,&quot;freq&quot;)) Cool, now we want to add colors. Take a look at the haploNet help page, paying particular attention to the pie argument: ?haploNet   So what we need is a matrix where rows are the different haplotypes and columns are the different locations. We can use the merged dataframe we made above along with the table command to produce this matrix: pie &lt;- table(merged$haplotype,merged$loc) head(pie) ## ## north south ## I 3 1 ## II 1 3 ## III 4 2 ## IV 3 4 ## V 4 8 ## VI 2 2 This table shows, for each haplotype, how many individuals come from the north and how many come from the south. Remember, this is completely made up data so we don’t expect any pattern here. Now we can use this to color the circles in the haplotype network, including adding a legend:   plot(net,size=attr(net,&quot;freq&quot;),pie=pie) legend(&quot;bottomleft&quot;, colnames(pie), col=rainbow(ncol(pie)), pch=19, ncol=2) 5.4 Homework   For homework you will create a haplotype network using the mtDNA data from Cliff et al. (2015). Here are the files you will need: cliff_metadata.csv contains sample IDs along with population information and haplotype inferred within the paper cliff_mtDNA.fasta contains mtDNA sequences from the paper.   5.4.1 Homework 5: Write a script that does the following: Read in the fasta file “mtDNA.fa” and the metadata file “metadata.csv” (hint: to read the .fa file you will use the command read.dna with argument format=“fasta”) Create a haplotype network (no colors) Create a table that shows the number of each haplotype in each population Create a haplotype network (with colors) Add a legend (this might look messy - that’s okay) "],["project-time.html", "Week 6 Project Time!", " Week 6 Project Time! No tutorial this week. We will spend time working on our independent projects. Rachael will be available during section time to help with troubleshooting "],["speciation-and-hybridization.html", "Week 7 Speciation and Hybridization 7.1 Match 7.2 Dealing with missing data 7.3 Writing your own functions 7.4 Hybrid allele frequencies 7.5 Making a PCA 7.6 Homework", " Week 7 Speciation and Hybridization 7.1 Match First of all, great news - no packages to install today!! The first command we’ll learn is match. match helps you match up two vectors that have the same values (or subset of values). For example, so far I’ve always given you metadata in the same order as your genotype files. But what if I didnt? We can use match to reorder the metadata so that it matches the genotype dataframe. Here’s how it works. First, let’s make two vectors with roughly the same values in different orders. A &lt;- c(&quot;FOX&quot;,&quot;BEAR&quot;,&quot;DOG&quot;,&quot;CAT&quot;,&quot;MOUSE&quot;) B &lt;- c(&quot;BEAR&quot;,&quot;CAT&quot;,&quot;MOUSE&quot;,&quot;FOX&quot;,&quot;DOG&quot;) match(A,B) ## [1] 4 1 5 2 3 match looks at each value in the first vector and returns the index of that value in the second vector. Note that the order matters: match(B,A) ## [1] 2 4 5 1 3 We can then use match to reorder the vectors to match: C &lt;- B[match(A,B)] C ## [1] &quot;FOX&quot; &quot;BEAR&quot; &quot;DOG&quot; &quot;CAT&quot; &quot;MOUSE&quot; So here we’ve taken the B vector and reordered it to match A.       7.2 Dealing with missing data Sometimes data aren’t perfect. Sometimes we have missing values. How do we deal with them, or at least find them? Let’s look at he airquality example dataset: data(&quot;airquality&quot;) head(airquality) ## Ozone Solar.R Wind Temp Month Day ## 1 41 190 7.4 67 5 1 ## 2 36 118 8.0 72 5 2 ## 3 12 149 12.6 74 5 3 ## 4 18 313 11.5 62 5 4 ## 5 NA NA 14.3 56 5 5 ## 6 28 NA 14.9 66 5 6 Notice that there are several NA values. The first thing we might want to do is to identify all rows that have NA values. We can identify rows with missing data in a particular column using the is.na function: is.na(airquality$Ozone) ## [1] FALSE FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE ## [17] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE TRUE TRUE FALSE FALSE FALSE FALSE TRUE ## [33] TRUE TRUE TRUE TRUE TRUE FALSE TRUE FALSE FALSE TRUE TRUE FALSE TRUE TRUE FALSE FALSE ## [49] FALSE FALSE FALSE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE FALSE FALSE FALSE ## [65] TRUE FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE ## [81] FALSE FALSE TRUE TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [97] FALSE FALSE FALSE FALSE FALSE TRUE TRUE FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE ## [113] FALSE FALSE TRUE FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [129] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [145] FALSE FALSE FALSE FALSE FALSE TRUE FALSE FALSE FALSE We can then ask for the indexes of those “TRUE” values and subset the data with those indexes: ind &lt;- is.na(airquality$Ozone) sub &lt;- airquality[ind,] head(sub) ## Ozone Solar.R Wind Temp Month Day ## 5 NA NA 14.3 56 5 5 ## 10 NA 194 8.6 69 5 10 ## 25 NA 66 16.6 57 5 25 ## 26 NA 266 14.9 58 5 26 ## 27 NA NA 8.0 57 5 27 ## 32 NA 286 8.6 78 6 1 More likely, though, we’ll want to want a subset without missing data. We can get this using ! which, in programming languages often makes a function the opposite meaning. So, !is.na helps us find entries that do not have missing data: ind &lt;- !is.na(airquality$Ozone) sub &lt;- airquality[ind,] head(sub) ## Ozone Solar.R Wind Temp Month Day ## 1 41 190 7.4 67 5 1 ## 2 36 118 8.0 72 5 2 ## 3 12 149 12.6 74 5 3 ## 4 18 313 11.5 62 5 4 ## 6 28 NA 14.9 66 5 6 ## 7 23 299 8.6 65 5 7 What if we want to look at missing data across the entire dataframe? First, we can use the function complete.cases to ask which rows have no missing data. We can also use the which function to ask for the indexes of those rows. These indexes could be used to subset the dataframe into only complete rows: complete.cases(airquality) ## [1] TRUE TRUE TRUE TRUE FALSE FALSE TRUE TRUE TRUE FALSE FALSE TRUE TRUE TRUE TRUE TRUE ## [17] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE FALSE FALSE FALSE TRUE TRUE TRUE TRUE FALSE ## [33] FALSE FALSE FALSE FALSE FALSE TRUE FALSE TRUE TRUE FALSE FALSE TRUE FALSE FALSE TRUE TRUE ## [49] TRUE TRUE TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE TRUE TRUE ## [65] FALSE TRUE TRUE TRUE TRUE TRUE TRUE FALSE TRUE TRUE FALSE TRUE TRUE TRUE TRUE TRUE ## [81] TRUE TRUE FALSE FALSE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE FALSE ## [97] FALSE FALSE TRUE TRUE TRUE FALSE FALSE TRUE TRUE TRUE FALSE TRUE TRUE TRUE TRUE TRUE ## [113] TRUE TRUE FALSE TRUE TRUE TRUE FALSE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## [129] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## [145] TRUE TRUE TRUE TRUE TRUE FALSE TRUE TRUE TRUE which(complete.cases(airquality)) ## [1] 1 2 3 4 7 8 9 12 13 14 15 16 17 18 19 20 21 22 23 24 28 29 30 31 ## [25] 38 40 41 44 47 48 49 50 51 62 63 64 66 67 68 69 70 71 73 74 76 77 78 79 ## [49] 80 81 82 85 86 87 88 89 90 91 92 93 94 95 99 100 101 104 105 106 108 109 110 111 ## [73] 112 113 114 116 117 118 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 ## [97] 138 139 140 141 142 143 144 145 146 147 148 149 151 152 153 sub &lt;- airquality[which(complete.cases(airquality)),] head(sub) ## Ozone Solar.R Wind Temp Month Day ## 1 41 190 7.4 67 5 1 ## 2 36 118 8.0 72 5 2 ## 3 12 149 12.6 74 5 3 ## 4 18 313 11.5 62 5 4 ## 7 23 299 8.6 65 5 7 ## 8 19 99 13.8 59 5 8 This is useful if you need the indexes to work across multiple dataframes (more on that later). But, if you just want to remove rows with missing data, you can just us na.omit: sub &lt;- na.omit(airquality) head(sub) ## Ozone Solar.R Wind Temp Month Day ## 1 41 190 7.4 67 5 1 ## 2 36 118 8.0 72 5 2 ## 3 12 149 12.6 74 5 3 ## 4 18 313 11.5 62 5 4 ## 7 23 299 8.6 65 5 7 ## 8 19 99 13.8 59 5 8 Finally, some functions will not automatically work if you have missing data. For example, look what happens when you try to fine the mean Ozone value across the dataset: mean(airquality$Ozone) ## [1] NA We need to tell the function what to do with NA values. The easiest thing to do is just ignore them: mean(airquality$Ozone,na.rm=T) ## [1] 42.12931       7.3 Writing your own functions So far, we’ve used a bunch of different functions that are provided by either the basic installation of R or various packages. But you can also write your own! Let’s say we are interested in a very specific metric calculated as follows: (mean of all values)/(number of non-missing datapoints)  We want to calculate this for each row. We know that we can do row by row calculations using the apply function, but how do we put this weird function into apply? First, we need to define our own function. This is how we do that: ourfunction &lt;- function(x) { top &lt;- mean(x,na.rm=T) bottom &lt;- length(!is.na(x)) metric &lt;- top/bottom return(top) } Here we can think of x as each row that will be passed through the function. At the end of the function we use return to tell the function what value we want to get out. We could apply this to any set of numbers: a &lt;- c(1,4,54,72,4,1) ourfunction(a) ## [1] 22.66667 Or we can apply our new function to each row in the dataframe: ourmetric &lt;- apply(airquality,MARGIN=1,ourfunction) ourmetric ## [1] 51.90000 40.16667 42.60000 68.91667 20.07500 23.98000 67.93333 33.96667 20.35000 57.32000 ## [11] 20.78000 61.28333 65.70000 64.31667 29.03333 74.08333 73.50000 30.40000 75.91667 25.28333 ## [21] 17.28333 74.60000 21.28333 37.66667 33.92000 73.98000 24.25000 24.66667 71.15000 76.28333 ## [31] 72.56667 75.92000 75.74000 66.82000 57.84000 64.92000 73.86000 43.45000 76.18000 80.13333 ## [41] 79.41667 75.98000 73.84000 46.66667 89.16000 86.70000 54.31667 72.78333 25.86667 40.25000 ## [51] 43.71667 52.06000 32.94000 40.12000 72.46000 49.80000 49.00000 32.66000 44.70000 31.58000 ## [61] 53.00000 83.35000 66.70000 61.36667 41.38000 56.43333 76.81667 76.68333 79.55000 80.45000 ## [71] 62.23333 49.52000 63.38333 52.98333 83.58000 28.55000 69.81667 70.88333 76.88333 64.01667 ## [81] 67.75000 21.98333 75.54000 83.70000 83.26667 76.00000 37.43333 44.33333 70.90000 75.73333 ## [91] 74.06667 73.53333 36.48333 22.96667 32.23333 36.58000 28.08000 34.32000 80.83333 72.38333 ## [101] 72.00000 68.12000 50.70000 58.91667 69.25000 55.61667 35.50000 34.05000 36.71667 41.23333 ## [111] 65.15000 58.38333 66.91667 26.88333 74.72000 62.95000 87.23333 69.33333 56.34000 70.28333 ## [121] 79.38333 76.88333 68.71667 61.81667 63.85000 60.63333 65.10000 41.73333 39.75000 63.15000 ## [131] 58.05000 59.15000 64.11667 65.98333 65.41667 61.88333 22.98333 38.58333 65.48333 58.13333 ## [141] 25.55000 61.38333 56.00000 59.60000 24.70000 49.71667 28.05000 24.60000 55.81667 54.24000 ## [151] 55.21667 45.16667 60.25000 7.4 Hybrid allele frequencies Today we’ll be looking at the data from Lamer et al. (2015). There are two files, a genotype table and metadata. Let’s first read in the genotype table: genofile &lt;- read.csv(&quot;data/lamar_genotypes.csv&quot;) head(genofile) ## ID snp1 snp2 snp3 snp4 snp5 snp6 snp7 snp8 snp9 snp10 snp11 snp12 snp13 snp14 snp15 snp16 snp17 ## 1 ILAG 1 0 0 0 0 0 0 0 0 0 0 0 0 0 NA 0 0 0 ## 2 ILAG 2 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## 3 ILAG 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## 4 ILAG 4 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## 5 ILAG 5 0 0 0 0 0 0 0 0 0 0 0 0 0 NA 0 0 0 ## 6 ILAG 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## snp18 snp19 snp20 snp21 snp22 snp23 snp24 snp25 snp26 snp27 snp28 snp29 snp30 snp31 snp32 snp33 ## 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## 2 0 0 0 0 0 0 0 0 NA 0 0 0 0 0 0 0 ## 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 ## 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## 5 0 0 0 0 0 NA NA NA NA NA NA NA NA NA NA NA ## 6 0 0 0 0 0 NA NA NA NA NA NA NA NA NA NA NA ## snp34 snp35 snp36 snp37 snp38 snp39 snp40 snp41 snp42 snp43 snp44 snp45 snp46 snp47 snp48 snp49 ## 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## 2 0 0 0 NA 0 0 0 0 0 0 0 0 0 0 0 0 ## 3 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 ## 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## 5 NA NA NA NA NA NA NA NA NA NA NA 0 0 0 1 0 ## 6 NA NA NA NA NA NA NA NA NA NA NA 0 0 0 0 0 ## snp50 snp51 snp52 snp53 snp54 snp55 snp56 snp57 ## 1 0 0 0 0 0 0 0 0 ## 2 0 0 0 0 0 0 0 0 ## 3 0 0 0 0 0 0 0 0 ## 4 0 0 0 0 0 0 0 0 ## 5 0 0 0 0 0 0 0 0 ## 6 0 0 0 0 0 0 0 0 Here the first column is a sample ID. The rest of the columns are genotypes at diagnostic SNPs that distinguish between the two carp species in the paper. Values are 0, 1, or 2 and indicate the number of bighead carp alleles at that SNP. So, for example, a 2 means that individual is homozygous for the bighead carp allele while a 0 means that individual is homozygous for the silver carp allele. Let’s split the dataframe into the sample IDs and a frame with just the genotypes: IDs &lt;- genofile[,1] genos &lt;- genofile[,2:ncol(genofile)] Now let’s read in the metadata: meta &lt;- read.csv(&quot;data/lamar_metadata.csv&quot;,stringsAsFactors = T) head(meta) ## ID Reach River Genetic.ID Field.ID Length Weight Age Birth.year ## 1 ILAG 566 LaGrange Reach Illinois Bx4SV &lt;NA&gt; NA NA NA NA ## 2 ILAG 567 LaGrange Reach Illinois Bx4SV &lt;NA&gt; NA NA NA NA ## 3 ILAG 568 LaGrange Reach Illinois Bx4SV &lt;NA&gt; NA NA NA NA ## 4 ILAG 569 LaGrange Reach Illinois SV &lt;NA&gt; NA NA NA NA ## 5 ILAG 570 LaGrange Reach Illinois SV &lt;NA&gt; NA NA NA NA ## 6 ILAG 571 LaGrange Reach Illinois SV &lt;NA&gt; NA NA NA NA Notice that the metadata and the genotypes are not in the same order. We’ll use match like we did above to reorder the metadata: ordermeta &lt;- meta[match(IDs,meta$ID),] Now that the genotype and metadata are aligned, we can do lots of different calculations. Maybe we want to calculate the fraction of bighead carp alleles for each individual. We can write a function for that: allelefreq &lt;- function(x) { length &lt;- length(na.omit(x)) sum &lt;- sum(x, na.rm=T) freq &lt;- sum/(length*2) return(freq) } The first line of the function calculates the length of the vector (the number of loci at which an individual is genotyped) - notice that we have omitted missing data. The second line simply adds the genotypes. We can do this because we know that hetorozygous individuals are coded as 1 and homozygous bighead carp individuals are coded as 2. The third row calculates the frequency of bighead carp alleles. Why do we have to multiple length by 2? Now we can apply that function to our genotype data: bigAlleles &lt;- apply(genos,1,allelefreq) summary(bigAlleles) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.00000 0.00000 0.01754 0.31639 0.99029 1.00000 Now we can do things like look at the mean frequency across different species classes (how accurate were our field IDs) or rivers (which river has the most introduced alleles?): aggregate(bigAlleles,list(ordermeta$Field.ID),mean) ## Group.1 x ## 1 BHCP 0.98366800 ## 2 Hybrid 0.76778692 ## 3 SVCP 0.02400816 ## 4 UNKN 0.28485652 a &lt;- aggregate(bigAlleles,list(ordermeta$River),mean)       7.5 Making a PCA Now we want to make a PCA to visualize the similarity between individuals. We can do this with the prcomp function, but this function doesn’t like missing data. There are some ways to deal with missing genotypes without having to discard them, but since we have a lot of data we will just remove individuals that have any missing data for now. We also have to subset the metadata to match: subgen &lt;- na.omit(genos) head(subgen) ## snp1 snp2 snp3 snp4 snp5 snp6 snp7 snp8 snp9 snp10 snp11 snp12 snp13 snp14 snp15 snp16 snp17 snp18 ## 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## 4 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## 19 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## 25 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## 26 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## 27 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## snp19 snp20 snp21 snp22 snp23 snp24 snp25 snp26 snp27 snp28 snp29 snp30 snp31 snp32 snp33 snp34 ## 3 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 ## 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## 19 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## 25 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## 26 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## 27 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## snp35 snp36 snp37 snp38 snp39 snp40 snp41 snp42 snp43 snp44 snp45 snp46 snp47 snp48 snp49 snp50 ## 3 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 ## 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## 19 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## 25 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## 26 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## 27 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## snp51 snp52 snp53 snp54 snp55 snp56 snp57 ## 3 0 0 0 0 0 0 0 ## 4 0 0 0 0 0 0 0 ## 19 0 0 0 0 0 0 0 ## 25 0 0 0 0 0 0 0 ## 26 0 0 0 0 0 0 0 ## 27 0 0 0 0 0 0 0 submeta &lt;- ordermeta[complete.cases(genos),] head(submeta) ## ID Reach River Genetic.ID Field.ID Length Weight Age Birth.year ## 1079 ILAG 3 LaGrange Reach Illinois Bx4SV SVCP 362 525 3 2006 ## 1080 ILAG 4 LaGrange Reach Illinois Bx4SV SVCP 371 600 1 2008 ## 1095 ILAG 19 LaGrange Reach Illinois SV SVCP 619 2550 4 2005 ## 1101 ILAG 25 LaGrange Reach Illinois SV SVCP 453 1050 2 2007 ## 1102 ILAG 26 LaGrange Reach Illinois SV SVCP 336 500 1 2008 ## 1103 ILAG 27 LaGrange Reach Illinois SV SVCP 364 600 1 2008 This works because we know that genos and ordermeta are in the same order. Now we can use this subsetted data to calculate a PCA and plot it: pca &lt;- prcomp(subgen) plot(pca$x) This doesn’t really mean anything if we don’t categorize the dots. For now, let’s color them by “River”: plot(pca$x,col=submeta$River,pch=19) legend(&quot;topright&quot;, legend=levels(submeta$River), pch=19, col=1:nlevels(submeta$River)) As you can see, there doesn’t seem to be obvious separation by River. What do you think is driving the patterns you see in this PCA?       7.6 Homework For homework we will continue using the data from Lamer et al. (2015).There are two relevant files: lamar_genotypes.csv Has SNP genotypes for each individual lamar_metadata.csv contains information about location of sampling   ###Homework 5: Write a script that does the following: Read in the “lamar_genotypes.csv” and “lamar_metadata.csv.” Reorder the metadata so that samples in the same order as in the genotypes file. Write a function that returns the proportion of data for each individual that is missing. Apply the function to your genotype data and print the summary. Create a PCA. Color by Field.ID and add a legend. "],["veterans-day.html", "Week 8 Veteran’s Day", " Week 8 Veteran’s Day No discussion this week! "],["sex-biased-gene-flow.html", "Week 9 Sex-biased gene flow 9.1 Multiple plots 9.2 Intro to this week’s data 9.3 Homework", " Week 9 Sex-biased gene flow 9.1 Multiple plots Often it’s useful to look at multiple plots side by side. Today we’ll learn an easy way to do that. Once again, we’ll use the Arthritis dataset. library(vcd) data(Arthritis) head(Arthritis) ## ID Treatment Sex Age Improved ## 1 57 Treated Male 27 Some ## 2 46 Treated Male 29 None ## 3 77 Treated Male 30 None ## 4 17 Treated Male 32 Marked ## 5 36 Treated Male 46 Marked ## 6 23 Treated Male 58 Marked   Maybe we want to compare outcomes for the treated vs. placebo patients. We could plot each like this: treated &lt;- subset(Arthritis,Treatment==&quot;Treated&quot;) table.treated &lt;- table(treated$Improved) barplot(table.treated) placebo &lt;- subset(Arthritis,Treatment==&quot;Placebo&quot;) table.placebo &lt;- table(placebo$Improved) barplot(table.placebo)   To really compare the results, though, it might be most useful to look at these side-by-side. We can to that by altering the graphical parameters: par(mfrow=c(1,2)) # 1 row and two columns of plots barplot(table.treated,main=&quot;Treated&quot;) barplot(table.placebo,main=&quot;Placebo&quot;) Now we can see that there is clearly more “Marked” improvement in the treated patients.       9.2 Intro to this week’s data Since you guys are all R experts now, this week you’ll use the documentation to figure out the analysis on your own. First, though, I’ll walk you through the data. We’re using the SNP data from the Portnoy et al. (2015) paper. There are two files: portnoy_genotypes.vcf contains the genotypes for each individual portnoy_metadata.csv contains metadata for each individual   You’ll need three different libraries (two new): install.packages(&quot;vcfR&quot;) install.packages(&quot;hierfstat&quot;) library(vcfR) library(hierfstat) library(adegenet)   The SNP data for today is a VCF (Variant Call Format) file. This is a very common format for analyzing raw SNP data. Take a look at this file in a text editor. There’s a lot of extra information that we do not need for our SNP analysis. We can use the vcfR library to read that file in and convert it to the genind format (remember we used this format to calculate heterozygosity?). This is the format that the adegenet package likes. v &lt;- read.vcfR(&quot;data/portnoy_genotypes.vcf&quot;) ## Scanning file to determine attributes. ## File attributes: ## meta lines: 64 ## header_line: 65 ## variant count: 5914 ## column count: 129 ## Meta line 64 read in. ## All meta lines processed. ## gt matrix initialized. ## Character matrix gt created. ## Character matrix gt rows: 5914 ## Character matrix gt cols: 129 ## skip: 0 ## nrows: 5914 ## row_num: 0 ## Processed variant 1000 Processed variant 2000 Processed variant 3000 Processed variant 4000 Processed variant 5000 Processed variant: 5914 ## All variants processed gen &lt;- vcfR2genind(v) gen ## /// GENIND OBJECT ///////// ## ## // 120 individuals; 5,914 loci; 11,838 alleles; size: 8.7 Mb ## ## // Basic content ## @tab: 120 x 11838 matrix of allele counts ## @loc.n.all: number of alleles per locus (range: 2-3) ## @loc.fac: locus factor for the 11838 columns of @tab ## @all.names: list of allele names for each locus ## @ploidy: ploidy of each individual (range: 2-2) ## @type: codom ## @call: adegenet::df2genind(X = t(x), sep = sep) ## ## // Optional content ## - empty - Let’s explore this file a little: dim(gen$tab) # gen$tab is a matrix where each row is an individual ## [1] 120 11838 head(gen$tab[,1:10]) ## E881_L109_46.0 E881_L109_46.1 E881_L109_71.0 E881_L109_71.1 E897_L100_57.0 E897_L100_57.1 ## AK_001 2 0 2 0 2 0 ## AK_003 2 0 2 0 2 0 ## AK_004 1 1 1 1 2 0 ## AK_005 1 1 1 1 2 0 ## AK_006 2 0 2 0 NA NA ## AK_007 1 1 1 1 1 1 ## E1071_L100_38.0 E1071_L100_38.1 E1071_L100_61.0 E1071_L100_61.1 ## AK_001 2 0 1 1 ## AK_003 0 2 2 0 ## AK_004 2 0 2 0 ## AK_005 2 0 2 0 ## AK_006 2 0 2 0 ## AK_007 2 0 2 0 rownames(gen$tab) #these are the sample names in order ## [1] &quot;AK_001&quot; &quot;AK_003&quot; &quot;AK_004&quot; &quot;AK_005&quot; &quot;AK_006&quot; &quot;AK_007&quot; &quot;AK_008&quot; &quot;AK_009&quot; &quot;AK_010&quot; &quot;AK_011&quot; ## [11] &quot;AK_012&quot; &quot;AK_013&quot; &quot;AK_014&quot; &quot;AK_015&quot; &quot;AK_016&quot; &quot;AK_017&quot; &quot;AK_018&quot; &quot;AK_019&quot; &quot;AK_020&quot; &quot;AK_021&quot; ## [21] &quot;AK_022&quot; &quot;AK_023&quot; &quot;AK_024&quot; &quot;AK_026&quot; &quot;AK_028&quot; &quot;AK_029&quot; &quot;AK_030&quot; &quot;AK_031&quot; &quot;AK_034&quot; &quot;AK_035&quot; ## [31] &quot;AK_036&quot; &quot;LK_001&quot; &quot;LK_003&quot; &quot;LK_005&quot; &quot;LK_006&quot; &quot;LK_008&quot; &quot;LK_009&quot; &quot;LK_010&quot; &quot;LK_011&quot; &quot;LK_012&quot; ## [41] &quot;LK_013&quot; &quot;LK_014&quot; &quot;LK_015&quot; &quot;LK_016&quot; &quot;LK_017&quot; &quot;LK_018&quot; &quot;LK_019&quot; &quot;LK_020&quot; &quot;LK_021&quot; &quot;LK_022&quot; ## [51] &quot;LK_023&quot; &quot;LK_024&quot; &quot;LK_025&quot; &quot;LK_026&quot; &quot;LK_027&quot; &quot;LK_028&quot; &quot;LK_029&quot; &quot;LK_030&quot; &quot;LK_031&quot; &quot;LK_032&quot; ## [61] &quot;LK_033&quot; &quot;LK_034&quot; &quot;NC_001&quot; &quot;NC_002&quot; &quot;NC_003&quot; &quot;NC_004&quot; &quot;NC_005&quot; &quot;NC_006&quot; &quot;NC_007&quot; &quot;NC_008&quot; ## [71] &quot;NC_010&quot; &quot;NC_011&quot; &quot;NC_013&quot; &quot;NC_014&quot; &quot;NC_015&quot; &quot;NC_016&quot; &quot;NC_017&quot; &quot;NC_018&quot; &quot;NC_019&quot; &quot;NC_022&quot; ## [81] &quot;NC_023&quot; &quot;NC_024&quot; &quot;NC_026&quot; &quot;NC_028&quot; &quot;PC_001&quot; &quot;PC_002&quot; &quot;PC_003&quot; &quot;PC_004&quot; &quot;PC_005&quot; &quot;PC_006&quot; ## [91] &quot;PC_007&quot; &quot;PC_008&quot; &quot;PC_009&quot; &quot;PC_010&quot; &quot;PC_011&quot; &quot;PC_012&quot; &quot;PC_013&quot; &quot;PC_014&quot; &quot;PC_015&quot; &quot;PC_016&quot; ## [101] &quot;PC_017&quot; &quot;PC_018&quot; &quot;PC_019&quot; &quot;PC_020&quot; &quot;PC_021&quot; &quot;PC_022&quot; &quot;PC_024&quot; &quot;PC_025&quot; &quot;PC_026&quot; &quot;PC_027&quot; ## [111] &quot;PC_028&quot; &quot;PC_029&quot; &quot;PC_030&quot; &quot;PC_031&quot; &quot;PC_032&quot; &quot;PC_036&quot; &quot;PC_037&quot; &quot;PC_038&quot; &quot;PC_039&quot; &quot;PC_040&quot;   Now we can take a look at the metadata: meta &lt;- read.csv(&quot;data/portnoy_metadata.csv&quot;) head(meta) ## Sample_Name Collection.Date Location.Code Locality Sex ## 1 NC_001 10/27/00 NC North Carolina Unknown ## 2 NC_002 10/27/00 NC North Carolina Unknown ## 3 NC_003 10/27/00 NC North Carolina Unknown ## 4 NC_004 10/27/00 NC North Carolina Unknown ## 5 NC_005 10/27/00 NC North Carolina Unknown ## 6 NC_006 10/27/00 NC North Carolina Unknown The first column is the sample names, but notice they are in a different order than in your genotype object. Other columns you might be interested in are “Locality” and “Sex”       ##Documentation The main package we will use for analysis is adegenet. Here is some helpful documentation. Some helpful sections:   5.4 Measuring and testing population structure   6.2 Performing a Principal Component Analysis on genind objects       9.3 Homework Use the data provided and the documentation to do the following: ###Homework 8: Write a script that does the following: Calculate Fst for males and females separately Create a 2-panel figure with separate PCAs for males and females. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
